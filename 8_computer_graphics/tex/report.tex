\documentclass[dvipdfmx]{jsarticle}

\usepackage{ascmac}
\usepackage{url}
\usepackage[dvipdfmx]{hyperref}
\usepackage{pxjahyper}
\usepackage[dvipdfmx]{graphicx}
\usepackage{float}
\usepackage{listings,jlisting}

\hypersetup{
  colorlinks=true,
  urlcolor=cyan,
  linkcolor=black
}

\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}


\begin{document}

\section{実験目的・課題}

次の画像(図\ref{fig:tapu})について、以下の3つの処理を行う。

\begin{itemize}
  \item 画像に対して輪郭検出を行う
  \item 画像に対してフィルタ処理を行う
  \item 画像に対して自動検出によるマスク処理を行う
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\hsize]{../pic/tapu.png}
  \caption{画像処理を行う画像}
  \label{fig:tapu}
\end{figure}


\section{実装方法}

\subsection{画像の二値化}

画像の二値化とは、画素の特定の要素において閾値を与え、
0か1に分類することである。
二値化された画像は、図\ref{fig:binarization}のように白黒画像なる。

pythonのOpenCVではthresholdという関数で画像の二値化を行うことが出来る。
第1引数に入力画像、第2引数に閾値、第3引数は閾値以上の値を持つ画素に
割り当てられる値、第4引数にいくつかある閾値処理のどれを使用するかのフラグを受け取る。
返り値は2つあり、使用した閾値と、二値化を適用した画像である。
入力画像はグレースケール画像でなければならず、画像を読み込むときに
imread(name,0)のように第2引数に0を与えると図\ref{fig:grayscale}のように
グレースケール画像として読み込むことが出来る。
\begin{figure}[H]
  \begin{minipage}{0.5\hsize}
    \centering
    \includegraphics[width=0.9\hsize]{../pic/binarization.jpg}
    \caption{大津の二値化を適用した図\ref{fig:tapu}}
    \label{fig:binarization}
  \end{minipage}
  \begin{minipage}{0.5\hsize}
    \centering
    \includegraphics[width=0.9\hsize]{../pic/grayscale.png}
    \caption{グレースケール画像}
    \label{fig:grayscale}
  \end{minipage}
\end{figure}


\subsection{輪郭検出}

輪郭とは、同じ色などについて境界に沿った連続する点をつなげることによって
形成される曲線のことである。
精度よく輪郭を検出するために、二値化画像を使用する。
以下のコードで輪郭を検出し、元画像に描画することが出来る。
\begin{lstlisting}
  import cv2
  img = cv2.imread('tapu.jpg')
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  ret, img_thres = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)
  img_cont, contours, hierarchy = cv2.findContours(img_thres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  cv2.drawContours(img, contours, -1, color=(0, 0, 255), thickness=2)
\end{lstlisting}

findContoursの第二引数には、全ての輪郭を同等に扱うRETR\_LIST、
入れ子構造になっている輪郭のもっとも外側の輪郭のみを検出するRETR\_EXTERNALなどを指定する。
第三引数では、全ての点を検出するCHAIN\_APPROX\_NONE、冗長な点を削除するCHAIN\_APPROX\_SIMPLE等を指定する。

\begin{figure}[htbp]
  \begin{minipage}{0.5\hsize}
    \begin{center}
      \includegraphics[width=0.9\hsize]{../pic/contour1_list.png}
    \end{center}
    \caption{RETR\_LISTで指定した場合}
    \label{fig:contour_list}
  \end{minipage}
  \begin{minipage}{0.5\hsize}
    \begin{center}
      \includegraphics[width=0.9\hsize]{../pic/contour1_external.png}
    \end{center}
    \caption{RETR\_EXTERNALで指定した場合}
    \label{fig:contour_external}
  \end{minipage}
\end{figure}

図\ref{fig:contour_list}に、findContoursの第二引数にRETR\_LISTを指定したもの、
図\ref{fig:contour_external}に、RETR\_EXTERNALを指定したものを示す。
図\ref{fig:contour_external}では、図\ref{fig:contour_list}では描画されていた
顔の中の輪郭などが検出されていないことがわかる。


\subsection{フィルタ処理}

画像に対してローパスフィルタ(LPF)やハイパスフィルタ(HPF)による
フィルタリングをすることが出来る。
LPFではノイズの除去や画像のぼかしが、
HPFではエッジの強調ができる。

filter2D関数は、入力画像とカーネル(フィルタ)の畳み込みを計算する。
式\ref{fomula:kernel}は、画像の平滑化を表す。
\begin{eqnarray}
  K ~=~ \frac{1}{25}
  \left[
    \begin{array}{rrrrr}
      1 & 1 & 1 & 1 & 1 \\
      1 & 1 & 1 & 1 & 1 \\
      1 & 1 & 1 & 1 & 1 \\
      1 & 1 & 1 & 1 & 1 \\
      1 & 1 & 1 & 1 & 1
    \end{array}
    \right]
  \label{fomula:kernel}
\end{eqnarray}

式\ref{fomula:kernel}を使ったフィルタリングを行うと、
各画素に対してその画素を中心に$5\times5$の画素を選択し、
その合計を25で割ったものを出力画像でのその画素の値にすることが出来る。

OpenCVではエッジ検出が出来るCannyや、
エッジを劣化させずに平滑化できるbilatetalFilterなど
多くのフィルタが利用できる。


\subsection{マスク処理}

読み込んだ画像は通常、画素ごとに[G,B,R]のarrayでデータを持つ。
これに対して図\ref{fig:mask1}のようなマスク画像を用意し
bitwise\_andをとると、図\ref{fig:masked1}のような画像が生成できる。

\begin{figure}[htbp]
  \begin{minipage}{0.5\hsize}
    \centering
    \includegraphics[width=0.9\hsize]{../pic/black.jpg}
    \caption{マスク画像}
    \label{fig:mask1}
  \end{minipage}
  \begin{minipage}{0.5\hsize}
    \centering
    \includegraphics[width=0.9\hsize]{../pic/tapu_icon.jpg}
    \caption{bitwise\_andを行った画像}
    \label{fig:masked1}
  \end{minipage}
\end{figure}

これはマスク画像の白い部分の画素は
[0b11111111,0b11111111,0b11111111]で表されるため、
どんな画素とandをとっても元の画像の値が残り、
逆に、黒い部分は[0b00000000,0b00000000,0b00000000]で
表されるためどんな値とandをとっても[0,0,0]つまり
黒になってしまうためである。


\section{結果と考察}

\subsection{輪郭検出}

以下のコードによって輪郭検出をし描画したものを図\ref{fig:contour}に示す。
6行目の処理ではcontourAreaという関数によって検出した輪郭の面積が
小さいものはリムーブするようにしている。
これによって図\ref{fig:contour_external}で見られた
あご周辺や髪先での点が消えていることがわかる。

\begin{lstlisting}
  import cv2
  img = cv2.imread('tapu.jpg')
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  ret, img_thres = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)
  img_cont, contours, hierarchy = cv2.findContours(img_thres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  contours = list(filter(lambda x: cv2.contourArea(x) > 100, contours))
  cv2.drawContours(img, contours, -1, color=(0, 0, 255), thickness=2)
\end{lstlisting}

\begin{figure}[htbp]
  \begin{minipage}{0.5\hsize}
    \centering
    \includegraphics[width=0.9\hsize]{../pic/contour2.png}
    \caption{面積100以上の領域のみ輪郭検出}
    \label{fig:contour}
  \end{minipage}
  \begin{minipage}{0.5\hsize}
    \centering
    \includegraphics[width=0.9\hsize]{../pic/contour3.png}
    \caption{手動で二値化をして輪郭検出をしたもの}
    \label{fig:contour2}
  \end{minipage}
\end{figure}


次に、画像の二値化の閾値を大津のアルゴリズムによる自動決定から手動で
設定したものを図\ref{fig:contour2}に示す。
図\ref{fig:contour}では検出できなかったマフラーや左側の
髪が検出できている。
これは大津の二値化では髪やマフラーがすべて閾値以下に判断されてしまい、
塗りつぶされてしまったためである。
大津の二値化では閾値が195になっていたのを180まで下げることによって一部髪の
輪郭も検出が出来るようになった。

\subsection{フィルタ処理}

式\ref{fomula:kernel}によって平滑化したものを図\ref{fig:smoothing}に示す。
図\ref{fig:tapu}と比べてぼやけているのがわかる。
次に、Canny関数を利用してエッジ検出をしたした画像を図\ref{fig:canny1}に示す。
エッジが検出されているが背景に多くのノイズが検出されてしまっていることがわかる。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\hsize]{../pic/smoothing.png}
  \caption{平滑化した画像}
  \label{fig:smoothing}
\end{figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\hsize]{../pic/canny1.png}
  \caption{エッジ検出した画像}
  \label{fig:canny1}
\end{figure}

この問題を解決するためには通常、画像の平滑化を行う。
図\ref{fig:smoothing}をCanny関数の引数として与えたものを
図\ref{fig:canny2}に示す。
この図から画像の平滑化をすることによってノイズを削除することが出来るという事がわかる。
なぜ平滑化をするとエッジ検出でのノイズが少なくなるかというのは、
エッジ検出は画素の値の不連続性を検出するものであるため、
平滑化を行うことで各画素の近傍との差が小さくなるため不連続性が小さくなるのだと考えられる。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\hsize]{../pic/canny2.png}
  \caption{平滑化してからエッジ検出をした画像}
  \label{fig:canny2}
\end{figure}

\newpage
\subsection{自動検出によるマスク処理}

画像を読み込み、背景を検出しそれをもとにマスク画像を作成し、
マスク処理を行う。
背景の検出は、輪郭検出をして領域面積が100000以上のもののみを残すことで
図\ref{fig:contour_large}のような輪郭を検出することが出来る。
これは、背景領域のみからなる輪郭であるため、条件を満たす。

次にこの輪郭からマスク画像を作成する。
drawContours関数はthicknesの値に負の数を指定すると輪郭の
内側を指定した色で塗りつぶすことが出来る。
これを使い元画像をコピーした画像の背景を塗りつぶす。

この塗りつぶされた画像の黒い部分のみを検出した二値化画像が
マスク画像になる。
黒い部分の抽出はinRange関数によって画素の値を[0,0,0]から[1,1,1]まで
のように指定して抽出する。
こうして作成したものを図\ref{fig:mask}に示す。

図\ref{fig:tapu}と図\ref{fig:masked1}のbitwise\_andをとった
画像を図\ref{fig:masked1}に示す。

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\hsize]{../pic/contour_large.png}
  \caption{面積10000以上の領域のみの輪郭}
  \label{fig:contour_large}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\hsize]{../pic/silhouette.png}
  \caption{マスク画像}
  \label{fig:mask}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\hsize]{../pic/tapu_bb.png}
  \caption{背景を自動検出してマスク処理を行った画像}
  \label{fig:masked}
\end{figure}

\begin{thebibliography}{10}
  \bibitem{1} OpenCV-Python チュートリアル文書

  \url{http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/index.html}

  \bibitem{2} OpenCV / findContours を使用して画像中のオブジェクトの輪郭を検出する方法

  \url{https://axa.biopapyrus.jp/ia/OpenCV/detect-contours.html}

  \bibitem{3} 描画関数

  \url{http://opencv.jp/opencv-2svn/py/core_drawing_functions.html}
\end{thebibliography}
\end{document}